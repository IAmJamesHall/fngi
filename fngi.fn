\ Fngi: bootstraps the fngi language.
\ Requires: spore.sp
\
\ Note: at this stage the language is severely restricted and several
\ pieces of the language are incomplete. Any CAPITAL items like FN, IF, LOOP
\ etc do not behave in the way their lower-case counterparts will behave.
\ Refer to spor.sp for all documentation.

$c_fngi

\ Stack operators. These are /not/ PRE since they directly modify the stack.
SFN swp      SMART IF() spor%SWP    ELSE $c1(SWP )   END ret;
SFN drp      SMART IF() spor%DRP    ELSE $c1(DRP )   END ret;
SFN ovr      SMART IF() spor%OVR    ELSE $c1(OVR )   END ret;
SFN dup      SMART IF() spor%DUP    ELSE $c1(DUP )   END ret;
SFN dupn     SMART IF() spor%DUPN   ELSE $c1(DUPN)   END ret;

\ Standard operators that use PRE syntax
SFN dvft PRE SMART IF() spor%DVFT   ELSE $c1(DVFT)   END ret;
SFN dvsr PRE SMART IF() spor%DVSR   ELSE $c1(DVSR)   END ret;
SFN inc  PRE SMART IF() spor%INC    ELSE $c1(INC )   END ret;
SFN inc2 PRE SMART IF() spor%INC2   ELSE $c1(INC2)   END ret;
SFN inc4 PRE SMART IF() spor%INC4   ELSE $c1(INC4)   END ret;
SFN dec  PRE SMART IF() spor%DEC    ELSE $c1(DEC )   END ret;
SFN inv  PRE SMART IF() spor%INV    ELSE $c1(INV )   END ret;
SFN neg  PRE SMART IF() spor%NEG    ELSE $c1(NEG )   END ret;
SFN not  PRE SMART IF() spor%NOT    ELSE $c1(NOT )   END ret;
SFN i1to4 PRE SMART IF() spor%CI1    ELSE $c1(CI1 )   END ret;
SFN i2to4 PRE SMART IF() spor%CI2    ELSE $c1(CI2 )   END ret;

SFN +    PRE SMART IF() spor%ADD    ELSE $c1(ADD )   END ret;
SFN -    PRE SMART IF() spor%SUB    ELSE $c1(SUB )   END ret;
SFN %    PRE SMART IF() spor%MOD    ELSE $c1(MOD )   END ret;
SFN <<   PRE SMART IF() spor%SHL    ELSE $c1(SHL )   END ret;
SFN >>   PRE SMART IF() spor%SHR    ELSE $c1(SHR )   END ret;
SFN bAnd PRE SMART IF() spor%BAND   ELSE $c1(BAND)   END ret;
SFN bOr  PRE SMART IF() spor%BOR    ELSE $c1(BOR )   END ret;
SFN xor  PRE SMART IF() spor%XOR    ELSE $c1(XOR )   END ret;
SFN lAnd PRE SMART IF() spor%LAND   ELSE $c1(LAND)   END ret;
SFN lOr  PRE SMART IF() spor%LOR    ELSE $c1(LOR )   END ret;
SFN ==   PRE SMART IF() spor%EQ     ELSE $c1(EQ  )   END ret;
SFN !=   PRE SMART IF() spor%NEQ    ELSE $c1(NEQ )   END ret;
SFN >=   PRE SMART IF() spor%GE_U   ELSE $c1(GE_U)   END ret;
SFN <    PRE SMART IF() spor%LT_U   ELSE $c1(LT_U)   END ret;
SFN *    PRE SMART IF() spor%MUL    ELSE $c1(MUL )   END ret;
SFN /    PRE SMART IF() spor%DIV_U  ELSE $c1(DIV_U ) END ret;

SFN xsw  PRE SMART assertNoInstant $c1(SZA+XSW) ret;
SFN xw   PRE SMART assertNoInstant $c1(SZA+XW)  ret;


\ memSet: {dst v len}   "dst = v"
\ memMove {dst src len} "dst = src"
\ memCmp: {&a &b len -> cmp}
SFN memSet  PRE SMART IF() dvft(D_memSet) ELSE lit(D_memSet) $c1(DVFT) END ret;
SFN memMove PRE SMART IF() dvsr(D_memSet) ELSE lit(D_memSet) $c1(DVSR) END ret;
SFN memCmp  PRE SMART IF() dvft(D_memCmp) ELSE lit(D_memCmp) $c1(DVFT) END ret;
SFN memClear PRE  0 swp; ret memSet(_, _) \ {addr len} clear memory

\ {a b} return if a < b
SFN retlt PRE SMART assertNoInstant(_) $c1(GE_U) $c1(RETZ) ret;

\ ftN(addr): fetch a value of sz N from address.
SFN ft1    PRE SMART IF() spor$(.1%FT) ELSE $c1(SZ1+FT) END ret;
SFN ft2    PRE SMART IF() spor$(.2%FT) ELSE $c1(SZ2+FT) END ret;
SFN ft4    PRE SMART IF() spor$(.4%FT) ELSE $c1(SZ4+FT) END ret;

\ srN(value, addr): store a value of sz N to address.
SFN sr1    PRE SMART IF() spor$(.1%SR) ELSE $c1(SZ1+SR) END ret;
SFN sr2    PRE SMART IF() spor$(.2%SR) ELSE $c1(SZ2+SR) END ret;
SFN sr4    PRE SMART IF() spor$(.4%SR) ELSE $c1(SZ4+SR) END ret;

SFN = SMART drp panic(E_cToken)    \ prevent hanging =
SFN ) SMART drp panic(E_cUnclosed) \ prevent hanging )
SFN setSysLogLvl PRE _SET sysLogLvl ret; \ {logLvl}
SFN setUsrLogLvl PRE _SET usrLogLvl ret; \ {logLvl}

\ FN_REF <function>: &fn (as literal or instant)
SFN FN_REF   SMART
  dictGetK; assertTyped(dup) \ {asInst &key}
  assertFn(dup)              \ {asInst &key}
  ft4(_)  swp;        \ {&fn asInst}
  ret(IF(\asInst) \(&fn) ELSE lit(\(&fn)) END)

FN strEq PRE \ {aLen &a bLen &b}
  \ $SZ2 INPUT aLen $SZ4 INPUT a
  $SZ2 INPUT bLen  $SZ4 INPUT b END_LOCALS
  swp \ {&a aLen}
  IF(\aLen != GET bLen)  drp; ret FALSE;  END \ {&a}
  ret(memCmp(\a, GET b, GET bLen) == 0)

SFN assertToken PRE \ {&zStr}
  ft1(dup); swp; inc(\zStr) \ {expectLen &expect}
  strEq(\expectLen, \(&expect), GET c_tokenLen, GET c_tokenBuf)
  (_, E_cNeedToken) $jmpl assert

$loc TOKEN_EQ | =|

SFN CONST  SMART assertNoInstant \ CONST <name> = <value>
  c_updateRKey; loc; \ {&key}: update c_rKey and initialize dict@name
  c_scan; assertToken(TOKEN_EQ) \ {&key}: expect "="
  \ c_single(TRUE) \ TODO: this should work... but isn't
  assert(c_number, E_cNeedNumber); \ {&key num}
  swp; ret sr4(\num, \(&key));

FN SET  SMART \ SET <name> = <value>
  $SZ4 LOCAL rKey  $SZ1 LOCAL isFromLocal END_LOCALS
  assertNoInstant;
  c_scan; anyDictGetK;  _SET isFromLocal  _SET rKey \ cache <name>
  c_scan; assertToken(TOKEN_EQ) \ "SET name ="
  xw(GET c_compFn) \ <value>
  ret _setImpl(GET rKey, GET isFromLocal)

FN globalReserve PRE  $SZ2 INPUT len END_LOCALS \ {len}
  memSet(GET c_gheap, 0, GET len) \ clear bytes
  SET c_gheap = (GET c_gheap + GET len);
  ret;

FN between PRE \ {value a b -> bool} value is between [a b)
  $SZ4 INPUT b   END_LOCALS \ {value a}
  ovr; swp; \ {value value a}
  IF(\value < \a)  drp; ret FALSE;  END
  ret(\value < GET b);

\ **********
\ * Block Allocator (BA)
\ The Block Allocator (BA) is used to allocate and free 4KiB blocks. It can
\ store up to 255 of them (almost a full MiB).
\
\ It's implementation architecture is built on the Byte Singly Linked List
\ (BSLL). The structure of a BSLL is an array of bytes, up to length 255.
\ Each byte can contain either 0xFF (BA_iNull) or the index of the next node.
\ At initialization, the root points to the first index and each index
\ points to the next index. Allocation is then simply popping indexes
\ from the SLL.
\
\ STRUCT BA [ \ size=10
\   indexes: &U1;   \ 0: pointer to indexes (up to 255 bytes)
\   blocks: APtr;   \ 4: pointer to data blocks, each of 4KiB
\   len: U1;        \ 5: number of indexes and blocks
\   root: U1;       \ 6: root free block, may be 0xFF if empty
\ ]

CONST NULL = 0;
CONST BA_iNull = 0xFF;
CONST BA_blockPo2 = 12;  \ 4KiB == 2^12
CONST BA_halfBlock = 2048;

\ STRUCT BA
\     BA_indexesOfs = 0;  \ indexes: APtr
CONST BA_blocksOfs  = 4;  \ blocks: APtr
CONST BA_lenOfs     = 8;  \ len: U1
CONST BA_rootOfs    = 9; \ root: U1

FN BA_iToPtr PRE \ {bi &ba -> &block}
  $SZ4 INPUT ba  END_LOCALS
  IF(dup\bi == BA_iNull) drp; ret NULL;  END \ {bi}
  assert(dup\bi < ft1(GET ba + BA_lenOfs), E_iBlock) \ {bi}
  ft4(GET ba + BA_blocksOfs); swp; \ {&firstBlk bi}
  ret(\firstBlk + (\bi << BA_blockPo2))

FN BA_isPtrValid PRE \ {&block &ba -> bool}
  $SZ4 INPUT block  $SZ4 INPUT ba  END_LOCALS
  ret between( \ block between [&firstBlk, &lastBlkEnd)
    GET block,
    ft4(GET ba + BA_blocksOfs), \ {&firstBlk}
    dup\firstBlk + (ft1(GET ba + BA_lenOfs) << BA_blockPo2),
  );

FN BA_ptrToI PRE \ {&blk &ba -> bi}
  $SZ4 INPUT blk  $SZ4 INPUT ba  END_LOCALS
  IF(not GET blk)  ret BA_iNull;  END
  assert(BA_isPtrValid(GET blk, GET ba), E_ptrBlk)
  ret((GET blk - ft4(GET ba + BA_blocksOfs)) >> BA_blockPo2);

SFN BA_iGet  PRE ret ft1(_ + ft4(_)) \ {bi &ba -> bi}
SFN BA_iSet  PRE  \ {value bi &ba}  set ba@bi = value
  _ + ft4(_) \ {value &index}
  ret sr1(_, _)

FN BA_init PRE \ {&ba}
  $SZ4 INPUT ba  $SZ1 LOCAL iLast  END_LOCALS
  SET iLast = dec(ft1(GET ba + BA_lenOfs));
  sr1(0, GET ba + BA_rootOfs); \ initialze root as index=0
  0 LOOP l0 \ {bi}
    IF(dup == GET iLast)
      BA_iNull; swp; ret BA_iSet(\BA_iNull, \bi, GET ba)
    END \ {bi}
    dup; inc(\bi); ovr; \(bi bi+1 bi)
    BA_iSet(\(bi+1), \bi, GET ba)
    inc(\bi) \ {bi+1}
  AGAIN l0

\ $setSysLogLvl(LOG_EXECUTE)
$BA_init(REF BA_kernel)

\ { &ba -> bi} alocate a block index
\ (returning a) root->a->b ===> root->b
FN BA_iAlloc PRE
  $SZ4 INPUT ba  END_LOCALS
  ft1(GET ba + BA_rootOfs) \ {biRoot}
  reteq(dup, BA_iNull) \ {biRoot} return BA_iNull if biRoot=BA_iNull
  sr1(BA_iGet(dup, GET ba), GET ba + BA_rootOfs); \ {biRoot} root=next node
  ret _;

\ {bi &ba} free a block index
\ (freeing bi=a) root->b  ===>  root->a->b
FN BA_iFree PRE
  $SZ1 INPUT bi  $SZ1 LOCAL biRoot  $SZ4 INPUT ba  END_LOCALS
  assert(BA_iNull != GET bi, E_iBlock)
  SET biRoot = ft1(GET ba + BA_rootOfs)
  BA_iSet(GET biRoot, GET bi, GET ba)  \ a -> b  (note: may be BA_iNull)
  ret sr1(GET bi, GET ba + BA_rootOfs) \ root -> a

SFN BA_alloc PRE \ {&ba -> &blockNullable}E
  BA_iAlloc(dup\ba); swp;
  ret BA_iToPtr(\bi, \ba);

SFN BA_free  PRE \ {&block &ba}
  swp; ovr; \ {&ba &block &ba}
  BA_ptrToI(\ba); swp; ret BA_iFree(\bi, \ba);

\ **********
\ * Singly Linked List (SLL)
\ Singly linked lists are used throughout fngi because of their simplicity
\ and extensibility. A singly linked list is a data structure that looks like
\ below, with how the operations affect it as well.
\
\ start    : root -> b -> NULL
\ push a   : root -> a -> b -> NULL
\ now pop a: root -> b -> NULL (return a)
\
\ STRUCT SLL [ next: &SLL ]
\ Note: root is just a pointer to a SLL with no data (&SLL)

FN SLL_pop  PRE \ {&root -> &a}: Pop a node from the SLL
  $SZ4 INPUT root  END_LOCALS
  ft4(GET root); \ {&a}
  retz(dup); \ {&a}
  ret sr4(ft4(dup), GET root); \ {&a} root->b

SFN SLL_push PRE \ {&a &root}: Push a node onto the SLL
  ovr; ovr;           \ {&a &root &a &root}
  ft4(\root); swp;    \ {&a &root &b &a}
  sr4(\b, \a);        \ a->b
  ret sr4(\a, \root); \ root->a

\ **********
\ * Arena Allocator (AA)
\ The arena budy allocator is built on top of the BA. It allows allocations of
\ power of 2 blocks of sizes 2^2 (4 bytes) to 2^12 (4KiB).
\
\ The AA keeps track of blocks it owns by using the BA's indexes (the same way
\ the BA keeps track of free blocks). When the arena is dropped, all (4KiB)
\ blocks are returned to the BA.
\
\ The AA does a best-effort job of trying to join freed blocks to prevent
\ fragmentation. However, it prioritizes known speed over reduction of
\ fragmentation. It's performance requires a maximum of 12 loops for any
\ request, except for freeing blocks which can require a BA index scan (rare).
\
\ If further fragmenetation reduction is required, a library can implement methods
\ to sort the freed areas and join conjoining ones. However the proper method to
\ eliminate fragmentation is to move any still-needed data to a new arena and
\ drop the fragmented one (obviously requiring careful programming).
\
\ ## Design:
\ The allocator has an array of pointers, each pointing to a larger po2.
\ Multiple free blocks in a single power of 2 are stored by creating a
\ singly-linked-list in the first 4 bytes of the free memory. Any freed (4KiB)
\ blocks are returned to the BA.
\
\ STRUCT AA [
\   bi: U1;  \ block index for allocated block.
\   _reserved1: U1;
\   _reserved2: U2;
\   ba: &BA;
\   \ Po2 2 - 11 Clever: &aa@2 is the 0th index (2nd power), &aa@11 is 11th
\   roots: arr[10; APtr];
\ ]

SFN sort2 PRE \ { a b -> _ _ } sort two values on the stack
  ovr; ovr; retlt(_, _) swp; ret;

\ {&a &b po2 -> bool} return whether blocks can be joined.
FN canBlocksMerge PRE
  $SZ1 INPUT po2  END_LOCALS
  ovr\a != align(dup\a, 1 << inc(GET po2)) \ {&a, &b, &a is on po2 boundary}
  IF(_) drp\b; drp\a; ret FALSE;  END
  ret(\a == (\b - (1 << GET po2))) \ return whether a is next to b

CONST AA_size     = 48;
CONST AA_baOfs    = 4;
CONST AA_rootsOfs = 8;

SFN AA_isValidPo2  PRE ret betweenIncl(_, 2, 12); \ {po2 -> bool}
SFN AA_assertPo2   PRE (AA_isValidPo2(_), E_aaPo2)$jmpl assert

FN AA_init PRE \ {&ba &aa}
  $SZ4 INPUT aa  END_LOCALS \ {&ba}
  sr4(\ba, GET aa + AA_baOfs); \ init ba
  (GET aa + AA_rootsOfs, 10 << 2)$jmpl memClear \ all roots=NULL

$(0 SZ4) GLOBAL AA_kernel;  $globalReserve(AA_size - 4)
$AA_init(REF BA_kernel, REF AA_kernel)

FN AA_findPo2 PRE \ {po2 &aa -> &free gotPo2}: find the closest available po2
  $SZ4 INPUT aa  END_LOCALS \ {po2}
  AA_assertPo2(dup\po2);
  LOOP l0  \ Find a free block of the appropriate size
    reteq(dup\po2, 12)                  \ maximum size
    retif(ft4((dup\po2 << 2) + GET aa)) \ non-null size
    inc(\po2)
  AGAIN l0

SFN AA_allocExactPo2 PRE \ {po2 &aa -> &free}: get an exact po2
  swp; \ {&aa po2}
  IF(dup\po2 == 12) drp\po2; BA_alloc(\aa + AA_baOfs);
  ELSE SLL_pop(\aa + (\po2 << 2))  END ret;

FN AA_allocPo2 PRE \ {po2 &aa -> &free} allocate memory of size po2
  $SZ1 INPUT po2  $SZ1 LOCAL gotPo2  $SZ4 INPUT aa  END_LOCALS
  SET gotPo2 = AA_findPo2(GET po2, GET aa);

  LOOP l1 \ Break the block until it is the right size.
    AA_allocExactPo2(GET gotPo2, GET aa); \ {&free}
    retz(dup) \ return if NULL
    reteq(GET po2, GET gotPo2) \ {&free}: return if correct po2

    SET gotPo2 = dec(GET gotPo2); \ {&free}: reduce gotPo2 since we're spliting in half
    \ The next cycle will return or divide the lowest free block
    SLL_push(dup\free + (1 << GET gotPo2), GET aa + (GET gotPo2 << 2))
    SLL_push(\free                       , GET aa + (GET gotPo2 << 2))
  AGAIN l1

\ FN AA_freePo2 PRE \ {&free po2 &aa}
\   $SZ1 INPUT po2  $SZ1 LOCAL gotPo2  $SZ4 INPUT aa  END_LOCALS \ {&free}
\   AA_assertPo2(GET po2); \ {&free}
\   LOOP l0 \ {&free} Merge free blocks while they are consecutive
\     IF(GET po2 == 12)  ret BA_free(GET aa + AA_baOfs);  END \ if block, just free that.
\     SLL_pop(dup, GET aa + (GET po2 << 2)) \ {&f, &fp} f=free fp=freePrev
\     IF(not dup) \ check null case of existing free
\       drp\fp; ret SLL_push(\f, GET aa + (GET po2 << 2));
\     END sort2(_, _); \ {&a &b} sort them for next checks.
\     IF(canBlocksMerge(ovr\a, ovr\b, GET po2))
\       drp\b; SET po2 = inc(GET po2); AGAIN l0 \ drop &b and treat as one
\     END \ cannot merge, just push both back and return.
\     SLL_push(\b, GET aa + (GET po2 << 2));
\     ret SLL_push(\a, GET aa + (GET po2 << 2));
\   \ END LOOP l0

$c_dictDump
